{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dataclasses import dataclass\n",
    "from pydantic import BaseModel, ConfigDict, SecretStr\n",
    "from langchain_core.language_models import BaseLanguageModel\n",
    "\n",
    "from configs.apis import APIS\n",
    "from libs.printing import eprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_MODELS = {\n",
    "    \"llm\": {\n",
    "        \"api\": \"openai\",  # MODELS[api]['key']\n",
    "        \"size\": \"default\",  # ['models']['llms'][size]\n",
    "    },\n",
    "    \"embedder\": {\n",
    "        \"api\": \"nvidia\",  # MODELS[api]['key']\n",
    "        \"size\": \"default\",  # ['models']['embedders'][size]\n",
    "    },\n",
    "}\n",
    "\n",
    "class ModelConfig(BaseModel):\n",
    "    \"\"\"Class for model configuration\"\"\"\n",
    "    type: str | None = \"llm\"\n",
    "    size: str | None = \"default\"\n",
    "    api: str | None = DEFAULT_MODELS[\"llm\"][\"api\"]\n",
    "    api_key: SecretStr | str | None = None\n",
    "\n",
    "    def __init__(self, *args, **kwargs): \n",
    "        self.type = kwargs.get(\"type\", \"llm\")\n",
    "        self.size = kwargs.get(\"size\", DEFAULT_MODELS[\"llm\"][\"size\"])\n",
    "        self.api = kwargs.get(\"size\", DEFAULT_MODELS[\"llm\"][\"api\"])\n",
    "        self.api_key = APIS[self.api][\"key\"].get_secret_value()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# @dataclass(slots=False)\n",
    "class Model(BaseModel):\n",
    "    \"\"\"Class for LLM and Embedder clients\"\"\"\n",
    "\n",
    "    config: ModelConfig = ModelConfig()\n",
    "    name: str | None\n",
    "    client: BaseLanguageModel | None\n",
    "\n",
    "    def __init__(self, model_config: ModelConfig = ModelConfig()):\n",
    "        self.config = model_config\n",
    "        self.name = MODELS[self.api][self.type][self.size]\n",
    "        self.client = BaseLanguageModel\n",
    "\n",
    "    def instantiate_client(self, agent_config):\n",
    "        if self.api == \"openai\":\n",
    "\n",
    "            self.client = ChatOpenAI(\n",
    "                model=self.name,\n",
    "                openai_api_key=self.api_key.get_secret_value(),\n",
    "                max_tokens=agent_config.max_tokens,\n",
    "                temperature=agent_config.temperature,\n",
    "                # top_p=agent_config.top_p,\n",
    "                max_retries=agent_config.max_retries,\n",
    "                timeout=agent_config.timeout,\n",
    "                response_format=agent_config.response_format,\n",
    "            )\n",
    "        elif self.api == \"nvidia\":\n",
    "            self.client = ChatNVIDIA(\n",
    "                model=self.name,\n",
    "                api_key=self.api_key.get_secret_value(),\n",
    "                temperature=agent_config.temperature,\n",
    "                # top_p=agent_config.top_p,\n",
    "                seed=agent_config.seed,\n",
    "                max_tokens=agent_config.max_tokens,\n",
    "            )\n",
    "        elif self.api == \"anthropic\":\n",
    "            self.client = ChatAnthropic(\n",
    "                model=self.name,\n",
    "                api_key=self.api_key.get_secret_value(),\n",
    "                temperature=agent_config.temperature,\n",
    "                # top_p=agent_config.top_p,\n",
    "                seed=agent_config.seed,\n",
    "                max_tokens=agent_config.max_tokens,\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Dict, Any\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Import the latest OpenAI LLM wrapper from Langchain.\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Task(BaseModel):\n",
    "    \"\"\"\n",
    "    Represents a Task assigned to an Agent.\n",
    "    \"\"\"\n",
    "    name: str\n",
    "    description: Optional[str] = None\n",
    "    parameters: Optional[Dict[str, Any]] = None\n",
    "\n",
    "    def execute(self, input_data: Optional[Dict[str, Any]] = None) -> str:\n",
    "        \"\"\"\n",
    "        Execute the task with the provided input data.\n",
    "        This creates a prompt or command string that the Agent's Model will process.\n",
    "        \"\"\"\n",
    "        data = input_data or self.parameters or {}\n",
    "        return f\"Executing task '{self.name}' with data: {data}\"\n",
    "\n",
    "\n",
    "class Model(BaseModel):\n",
    "    \"\"\"\n",
    "    Represents an LLM backend following the latest OpenAI and Langchain API best practices.\n",
    "    \n",
    "    This model wraps an OpenAI language model instance using Langchain's OpenAI LLM.\n",
    "    \"\"\"\n",
    "    name: str\n",
    "    version: Optional[str] = \"1.0\"\n",
    "    openai_api_key: Optional[str] = None\n",
    "    model_name: Optional[str] = None\n",
    "\n",
    "    # Private field for the underlying Langchain LLM instance.\n",
    "    _llm: Optional[OpenAI] = None\n",
    "\n",
    "    class Config:\n",
    "        # Allow non-Pydantic types (like the Langchain LLM instance).\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    def init_llm(self) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the Langchain OpenAI LLM using the provided API key and model name.\n",
    "        \"\"\"\n",
    "        if not self.openai_api_key or not self.model_name:\n",
    "            raise ValueError(\"Both 'openai_api_key' and 'model_name' must be provided to initialize the LLM.\")\n",
    "        self._llm = OpenAI(openai_api_key=self.openai_api_key, model_name=self.model_name)\n",
    "\n",
    "    def predict(self, prompt: str, **kwargs) -> str:\n",
    "        \"\"\"\n",
    "        Generate a response for the given prompt using the LLM.\n",
    "        \n",
    "        This method delegates to the Langchain LLM instance, automatically initializing it if needed.\n",
    "        \"\"\"\n",
    "        if self._llm is None:\n",
    "            self.init_llm()\n",
    "        return self._llm(prompt, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a = File(\"erik.hodges/yes/filename.csv\")\n",
    "\n",
    "a.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Agent(BaseModel):\n",
    "    \"\"\"\n",
    "    Represents an Agent that executes a Task using a Model.\n",
    "    \n",
    "    In an Observer pattern, each Agent acts as an observer that receives notifications from the Team.\n",
    "    \"\"\"\n",
    "    name: str\n",
    "    task: Task\n",
    "    model: Model\n",
    "    team: Optional[\"Team\"] = None  # Forward reference to Team\n",
    "\n",
    "    def perform_task(self, input_data: Optional[Dict[str, Any]] = None) -> str:\n",
    "        \"\"\"\n",
    "        Executes the Agent's Task using its Model.\n",
    "        \n",
    "        The prompt is generated by the Task, the response is produced by the Model, and the result is logged by the Team.\n",
    "        \"\"\"\n",
    "        prompt = self.task.execute(input_data)\n",
    "        response = self.model.predict(prompt)\n",
    "        if self.team:\n",
    "            self.team.log_action(self.name, \"performed_task\", response)\n",
    "        return response\n",
    "\n",
    "    def set_team(self, team: \"Team\") -> None:\n",
    "        \"\"\"\n",
    "        Set the Team (subject) for the Agent (observer).\n",
    "        \"\"\"\n",
    "        self.team = team\n",
    "\n",
    "    def update(self, event: Dict[str, str]) -> None:\n",
    "        \"\"\"\n",
    "        Observer callback method invoked by the Team when an event occurs.\n",
    "        \n",
    "        In a more complex implementation, an Agent could analyze events to update its internal state or trigger actions.\n",
    "        \"\"\"\n",
    "        print(f\"Agent '{self.name}' received update: {event}\")\n",
    "\n",
    "\n",
    "class Team(BaseModel):\n",
    "    \"\"\"\n",
    "    Represents a Team of Agents working toward a shared Goal.\n",
    "    \n",
    "    This class follows the Observer design pattern:\n",
    "      - **Subject:** The Team maintains a list of Agents (observers).\n",
    "      - **Observers:** Each Agent registers with the Team and is notified of events.\n",
    "      \n",
    "    **Langgraph Integration:**  \n",
    "      The Team can be interpreted as a graph, where each Agent is a node.  \n",
    "      Communication events (such as broadcasts) can be represented as edges between nodes.\n",
    "      The `to_graph` method returns a simple graph representation compatible with the Langgraph library.\n",
    "    \"\"\"\n",
    "    name: str\n",
    "    goal: str\n",
    "    agents: List[Agent] = Field(default_factory=list)\n",
    "    log: List[Dict[str, str]] = Field(default_factory=list)\n",
    "\n",
    "    def register_agent(self, agent: Agent) -> None:\n",
    "        \"\"\"\n",
    "        Registers an Agent with the Team, logs the registration, and notifies all observers.\n",
    "        \"\"\"\n",
    "        agent.set_team(self)\n",
    "        self.agents.append(agent)\n",
    "        self.log_action(agent.name, \"registered\", f\"Agent '{agent.name}' registered to team '{self.name}'.\")\n",
    "        self.notify_observers({\"event\": \"agent_registered\", \"agent\": agent.name})\n",
    "\n",
    "    def unregister_agent(self, agent: Agent) -> None:\n",
    "        \"\"\"\n",
    "        Unregisters an Agent from the Team, logs the unregistration, and notifies observers.\n",
    "        \"\"\"\n",
    "        self.agents = [a for a in self.agents if a.name != agent.name]\n",
    "        self.log_action(agent.name, \"unregistered\", f\"Agent '{agent.name}' unregistered from team '{self.name}'.\")\n",
    "        self.notify_observers({\"event\": \"agent_unregistered\", \"agent\": agent.name})\n",
    "\n",
    "    def log_action(self, agent: str, action: str, response: str) -> None:\n",
    "        \"\"\"\n",
    "        Logs an action performed by an Agent and notifies observers of the event.\n",
    "        \"\"\"\n",
    "        event = {\"agent\": agent, \"action\": action, \"response\": response}\n",
    "        self.log.append(event)\n",
    "        self.notify_observers(event)\n",
    "\n",
    "    def broadcast(self, sender: Agent, message: str) -> None:\n",
    "        \"\"\"\n",
    "        Broadcasts a message from one Agent to all others in the Team.\n",
    "        \"\"\"\n",
    "        self.log_action(sender.name, \"broadcast\", message)\n",
    "        event = {\"event\": \"broadcast\", \"sender\": sender.name, \"message\": message}\n",
    "        self.notify_observers(event)\n",
    "\n",
    "    def notify_observers(self, event: Dict[str, str]) -> None:\n",
    "        \"\"\"\n",
    "        Notifies all registered Agents (observers) of a given event.\n",
    "        \"\"\"\n",
    "        for agent in self.agents:\n",
    "            agent.update(event)\n",
    "\n",
    "    def to_graph(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Returns a graph representation of the Team.\n",
    "        \n",
    "        - **Nodes:** The names of all registered Agents.\n",
    "        - **Edges:** Derived from broadcast events in the log; for example, a broadcast from one agent to all others.\n",
    "        \n",
    "        This representation is designed to be used with the Langgraph library for visualization and further orchestration.\n",
    "        \"\"\"\n",
    "        nodes = [agent.name for agent in self.agents]\n",
    "        edges = []\n",
    "        for entry in self.log:\n",
    "            if entry.get(\"action\") == \"broadcast\":\n",
    "                sender = entry.get(\"agent\")\n",
    "                for node in nodes:\n",
    "                    if node != sender:\n",
    "                        edges.append((sender, node))\n",
    "        return {\"nodes\": nodes, \"edges\": edges}\n",
    "\n",
    "    def get_log(self) -> List[Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Returns the log of all actions/events in the Team.\n",
    "        \"\"\"\n",
    "        return self.log\n",
    "\n",
    "\n",
    "# Resolve forward references between Agent and Team.\n",
    "Agent.update_forward_refs()\n",
    "Team.update_forward_refs()\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# Example usage (for testing)\n",
    "# ==============================\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a team with a shared goal.\n",
    "    team = Team(name=\"Beta\", goal=\"Collaborative problem solving\")\n",
    "    \n",
    "    # Create a Model instance using the latest OpenAI API via Langchain.\n",
    "    model = Model(\n",
    "        name=\"OpenAI-GPT\",\n",
    "        version=\"4.0\",\n",
    "        openai_api_key=\"your-api-key\",  # Replace with your actual API key.\n",
    "        model_name=\"gpt-4\"\n",
    "    )\n",
    "    \n",
    "    # Create two Tasks.\n",
    "    task1 = Task(\n",
    "        name=\"Data Analysis\",\n",
    "        description=\"Analyze the provided dataset\",\n",
    "        parameters={\"data\": \"dataset.csv\"}\n",
    "    )\n",
    "    task2 = Task(\n",
    "        name=\"Report Generation\",\n",
    "        description=\"Generate a report from analysis\",\n",
    "        parameters={\"template\": \"summary\"}\n",
    "    )\n",
    "    \n",
    "    # Create two Agents, each with a different Task.\n",
    "    agent1 = Agent(name=\"Agent 1\", task=task1, model=model)\n",
    "    agent2 = Agent(name=\"Agent 2\", task=task2, model=model)\n",
    "    \n",
    "    # Register the Agents with the Team.\n",
    "    team.register_agent(agent1)\n",
    "    team.register_agent(agent2)\n",
    "    \n",
    "    # Agents perform their assigned tasks.\n",
    "    print(\"Agent 1 task result:\")\n",
    "    print(agent1.perform_task())\n",
    "    print(\"\\nAgent 2 task result:\")\n",
    "    print(agent2.perform_task())\n",
    "    \n",
    "    # One Agent broadcasts a message to the entire team.\n",
    "    team.broadcast(sender=agent1, message=\"Data analysis complete. Proceeding to report generation.\")\n",
    "    \n",
    "    # Display the graph representation of the Team.\n",
    "    print(\"\\nTeam Graph Representation:\")\n",
    "    print(team.to_graph())\n",
    "    \n",
    "    # Print the Team's log of actions/events.\n",
    "    print(\"\\nTeam Log:\")\n",
    "    for log_entry in team.get_log():\n",
    "        print(log_entry)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
